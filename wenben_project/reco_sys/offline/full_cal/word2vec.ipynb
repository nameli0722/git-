{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# 如果当前代码文件运行测试需要加入修改路径，避免出现后导包问题\n",
    "BASE_DIR = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "sys.path.insert(0, os.path.join(BASE_DIR))\n",
    "\n",
    "PYSPARK_PYTHON = \"/miniconda2/envs/reco_sys/bin/python\"\n",
    "# 当存在多个版本时，不指定很可能会导致出错\n",
    "os.environ[\"PYSPARK_PYTHON\"] = PYSPARK_PYTHON\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = PYSPARK_PYTHON\n",
    "\n",
    "from offline import SparkSessionBase\n",
    "from settings.default import CHANNEL_INFO\n",
    "from pyspark.ml.feature import Word2Vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainWord2VecModel(SparkSessionBase):\n",
    "\n",
    "    SPARK_APP_NAME = \"Word2Vec\"\n",
    "    #SPARK_URL = \"yarn\"\n",
    "\n",
    "    ENABLE_HIVE_SUPPORT = True\n",
    "\n",
    "    def __init__(self):\n",
    "        self.spark = self._create_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = TrainWord2VecModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation(partition):\n",
    "    import os\n",
    "    import re\n",
    "\n",
    "    import jieba\n",
    "    import jieba.analyse\n",
    "    import jieba.posseg as pseg\n",
    "    import codecs\n",
    "\n",
    "    abspath = \"/root/words\"\n",
    "\n",
    "    # 结巴加载用户词典\n",
    "    userDict_path = os.path.join(abspath, \"ITKeywords.txt\")\n",
    "    jieba.load_userdict(userDict_path)\n",
    "\n",
    "    # 停用词文本\n",
    "    stopwords_path = os.path.join(abspath, \"stopwords.txt\")\n",
    "\n",
    "    def get_stopwords_list():\n",
    "        \"\"\"返回stopwords列表\"\"\"\n",
    "        stopwords_list = [i.strip()\n",
    "                          for i in codecs.open(stopwords_path).readlines()]\n",
    "        return stopwords_list\n",
    "\n",
    "    # 所有的停用词列表\n",
    "    stopwords_list = get_stopwords_list()\n",
    "\n",
    "    # 分词\n",
    "    def cut_sentence(sentence):\n",
    "        \"\"\"对切割之后的词语进行过滤，去除停用词，保留名词，英文和自定义词库中的词，长度大于2的词\"\"\"\n",
    "        # print(sentence,\"*\"*100)\n",
    "        # eg:[pair('今天', 't'), pair('有', 'd'), pair('雾', 'n'), pair('霾', 'g')]\n",
    "        seg_list = pseg.lcut(sentence)\n",
    "        seg_list = [i for i in seg_list if i.word not in stopwords_list]\n",
    "        filtered_words_list = []\n",
    "        for seg in seg_list:\n",
    "            # print(seg)\n",
    "            if len(seg.word) <= 1:\n",
    "                continue\n",
    "            elif seg.flag == \"eng\":\n",
    "                if len(seg.word) <= 2:\n",
    "                    continue\n",
    "                else:\n",
    "                    filtered_words_list.append(seg.word)\n",
    "            elif seg.flag.startswith(\"n\"):\n",
    "                filtered_words_list.append(seg.word)\n",
    "            elif seg.flag in [\"x\", \"eng\"]:  # 是自定一个词语或者是英文单词\n",
    "                filtered_words_list.append(seg.word)\n",
    "        return filtered_words_list\n",
    "\n",
    "    for row in partition:\n",
    "        sentence = re.sub(\"<.*?>\", \"\", row.sentence)    # 替换掉标签数据\n",
    "        words = cut_sentence(sentence)\n",
    "        yield row.article_id, row.channel_id, words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.spark.sql('use article')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = w2v.spark.sql('select * from article_data where channel_id=18 limit 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df = article.rdd.mapPartitions(segmentation).toDF(['article_id', 'channel_id', 'words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_word2vec = Word2Vec(vectorSize=100, inputCol=\"words\", outputCol=\"model\", minCount=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = new_word2vec.fit(words_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+\n",
      "|       word|              vector|\n",
      "+-----------+--------------------+\n",
      "|       函数参数|[0.00343297771178...|\n",
      "|  recipient|[0.01848481036722...|\n",
      "|   register|[0.01116304472088...|\n",
      "|        fib|[0.04160280898213...|\n",
      "|         函数|[0.02662521973252...|\n",
      "|     encode|[-0.0152690997347...|\n",
      "|    network|[0.01590051129460...|\n",
      "|         __|[-0.0548076145350...|\n",
      "|     xrange|[0.08385339379310...|\n",
      "|      Proof|[-0.0322913937270...|\n",
      "|        表达式|[-0.0057290056720...|\n",
      "|         时间|[-0.0049802274443...|\n",
      "|Transaction|[-0.0103443199768...|\n",
      "|    request|[-0.0376213230192...|\n",
      "|       HTTP|[0.00963569525629...|\n",
      "|        ram|[-0.0141640864312...|\n",
      "|  timestamp|[-0.0133891822770...|\n",
      "|         交易|[0.01113164052367...|\n",
      "|       join|[0.04276565462350...|\n",
      "| identifier|[-0.0140685094520...|\n",
      "+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_model.getVectors().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(word='函数参数', vector=DenseVector([0.0034, 0.0326, -0.0283, 0.0064, 0.0449, 0.0189, 0.0449, 0.0466, -0.0078, -0.0199, 0.0116, -0.0082, 0.0009, -0.0074, -0.0204, 0.0375, -0.0054, 0.0126, -0.0307, -0.0104, -0.0286, 0.0193, -0.0121, 0.0144, 0.0045, -0.0144, 0.0212, 0.0249, -0.0235, 0.0024, 0.0339, -0.0027, 0.0351, -0.0383, -0.0086, 0.003, -0.0169, 0.0247, 0.0281, -0.0105, -0.0006, 0.017, 0.0226, 0.0251, 0.0434, -0.0254, -0.0021, -0.01, -0.0097, -0.0008, -0.0223, -0.018, -0.0084, 0.0101, -0.0217, 0.0192, 0.0474, -0.0272, 0.0127, -0.0148, 0.0011, -0.0178, -0.0148, -0.0284, -0.0237, -0.0052, -0.0357, 0.0189, 0.0296, 0.0276, -0.0301, -0.0073, -0.0172, -0.0257, 0.0197, -0.0234, -0.0208, -0.0417, -0.0325, -0.0309, 0.0016, 0.0173, 0.0152, 0.0114, 0.0238, -0.0319, -0.0321, -0.0309, 0.0104, 0.0361, 0.0213, 0.0117, 0.0004, 0.0013, 0.0393, -0.0289, 0.052, -0.0416, -0.0049, -0.0189])),\n",
       " Row(word='recipient', vector=DenseVector([0.0185, -0.0973, 0.102, -0.0404, -0.1631, -0.0154, -0.1834, -0.1838, 0.007, 0.1457, -0.0505, -0.0468, 0.0461, -0.0275, 0.0521, -0.1914, -0.057, -0.0213, 0.126, 0.086, 0.1363, 0.0131, 0.0454, -0.0939, 0.0334, 0.1519, -0.0376, -0.1407, 0.0691, 0.0269, -0.1776, -0.092, -0.1738, 0.1966, 0.0811, -0.0014, 0.0198, -0.087, -0.1725, 0.0305, 0.0234, 0.0143, -0.1312, -0.0806, -0.2399, 0.0513, 0.0201, 0.0287, 0.0542, 0.0074, 0.0243, 0.0577, -0.0362, 0.0619, 0.1067, -0.0731, -0.2104, 0.1458, -0.0763, 0.0887, -0.083, -0.0353, 0.1152, 0.036, 0.0843, 0.0446, 0.1495, -0.0714, -0.0877, -0.0928, 0.0429, -0.0648, 0.1448, 0.0797, -0.0747, 0.1513, 0.0945, 0.084, 0.1407, 0.1159, -0.1023, 0.0007, -0.0691, -0.0705, -0.1613, 0.178, 0.1653, 0.1714, -0.1145, -0.1809, -0.0246, -0.0925, -0.0539, -0.0574, -0.1736, 0.1435, -0.1265, 0.2338, -0.0243, 0.0638])),\n",
       " Row(word='register', vector=DenseVector([0.0112, 0.0092, -0.0139, 0.0142, 0.0123, -0.0225, 0.033, 0.008, 0.0049, -0.0558, -0.012, 0.0456, -0.0242, 0.0103, -0.0064, 0.0517, 0.0394, 0.0001, -0.0287, -0.0258, -0.0196, -0.0269, 0.0127, 0.0344, -0.0321, -0.0347, -0.004, 0.0124, -0.0072, 0.0009, 0.0506, 0.0393, 0.032, -0.0512, -0.032, -0.0079, 0.0044, -0.0001, 0.0407, 0.0068, 0.0032, -0.0113, 0.0355, -0.0093, 0.0514, 0.0209, 0.0036, 0.01, -0.0162, 0.0076, 0.0382, 0.013, 0.0011, -0.0409, -0.0045, -0.0054, 0.0212, -0.0464, 0.0119, -0.0154, 0.0471, 0.0408, -0.0371, 0.0199, 0.0076, -0.0309, -0.0211, 0.0114, -0.0024, 0.0165, -0.0045, 0.0198, -0.0277, -0.018, 0.0093, -0.0308, 0.0041, 0.0002, -0.0243, -0.0164, 0.0369, -0.0232, 0.0105, 0.021, 0.0598, -0.038, -0.0289, -0.0459, 0.0302, 0.0111, -0.0294, 0.0304, 0.0047, 0.0305, 0.0092, -0.0196, 0.0078, -0.0514, 0.0178, 0.0188])),\n",
       " Row(word='fib', vector=DenseVector([0.0416, 0.0557, -0.0487, 0.019, 0.1125, -0.0481, 0.1272, 0.1451, -0.0148, -0.2382, -0.1188, 0.1354, 0.0037, 0.0967, 0.0246, 0.1669, 0.1487, 0.0658, -0.1252, -0.0857, 0.015, -0.0883, 0.0816, 0.1417, -0.0381, -0.2288, -0.0295, 0.0906, -0.0043, -0.0656, 0.1141, 0.0818, 0.0902, -0.1246, -0.1433, 0.0648, 0.0125, -0.0166, 0.1533, 0.0655, 0.0568, -0.0422, 0.0476, 0.0336, 0.2646, 0.0358, -0.0284, -0.0092, 0.0182, 0.0477, 0.0705, -0.0054, -0.0461, -0.0506, -0.061, 0.012, 0.1659, -0.1452, 0.0736, 0.0301, 0.1073, 0.0196, -0.1202, 0.051, -0.0725, -0.0953, -0.1622, 0.048, -0.0467, 0.039, -0.0105, 0.1095, -0.0897, -0.1221, -0.0944, -0.0847, 0.0264, -0.0215, -0.1532, -0.0707, 0.1055, -0.0541, 0.0612, 0.1297, 0.1748, -0.133, 0.0576, -0.132, 0.1394, 0.1063, -0.1266, 0.1507, 0.0381, -0.0531, 0.0378, -0.0861, 0.0921, -0.2153, 0.1191, -0.004])),\n",
       " Row(word='函数', vector=DenseVector([0.0266, 0.0889, -0.0845, 0.0221, 0.1379, 0.0246, 0.1262, 0.1278, -0.0134, -0.1106, -0.0274, 0.0336, 0.0085, 0.0086, -0.0347, 0.1354, 0.0266, 0.0413, -0.0947, -0.0503, -0.0591, 0.0094, 0.0198, 0.0797, -0.003, -0.1013, 0.041, 0.0719, -0.0443, 0.003, 0.1053, 0.0306, 0.0899, -0.1171, -0.0525, 0.024, -0.0189, 0.0414, 0.0927, -0.0005, 0.0181, 0.0426, 0.0636, 0.0642, 0.1657, -0.0419, -0.0035, -0.0253, -0.0287, 0.0053, -0.0201, -0.0355, -0.0307, 0.0073, -0.0551, 0.0331, 0.1363, -0.1224, 0.0394, -0.0044, 0.0382, -0.0198, -0.0738, -0.0424, -0.0532, -0.0538, -0.1263, 0.0722, 0.0522, 0.0695, -0.0596, 0.0168, -0.0439, -0.0912, 0.0092, -0.078, -0.047, -0.0859, -0.117, -0.0717, 0.0419, 0.01, 0.055, 0.0611, 0.1202, -0.1016, -0.0376, -0.1094, 0.0669, 0.0979, -0.0048, 0.0754, 0.014, -0.0051, 0.096, -0.0796, 0.1439, -0.153, 0.0375, -0.0417]))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.getVectors().rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Word2VecModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_id = 18\n",
    "channel = \"python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_model = Word2VecModel.load('file:///root/bak/modelsbak/word2vec_model/channel_%d_%s.word2vec' % (channel_id, channel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = wv_model.getVectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(word='广义', vector=DenseVector([0.2891, -0.1201, 0.2581, 0.0197, 0.0078, 0.0804, -0.1394, 0.0727, -0.0221, 0.284, -0.044, -0.0103, 0.0481, -0.3808, 0.1075, -0.2184, -0.2475, 0.1366, -0.2287, -0.2782, 0.2139, 0.0117, -0.09, -0.0209, -0.0138, -0.0915, 0.0368, -0.1199, 0.0512, 0.2744, -0.0565, 0.3728, 0.3951, -0.005, 0.0649, -0.3247, -0.1027, 0.2947, -0.0416, -0.017, 0.3251, 0.011, 0.1175, 0.2295, -0.0771, -0.253, -0.4119, 0.0251, 0.086, -0.0341, -0.0386, 0.4387, -0.108, -0.0404, -0.2936, -0.0651, -0.1807, -0.0766, -0.0907, -0.2319, -0.0095, -0.0735, -0.4099, 0.2474, 0.1552, -0.3484, 0.0463, -0.256, -0.1195, -0.0489, -0.1076, -0.1659, -0.0391, 0.16, -0.2375, -0.2284, 0.0499, 0.3306, -0.1903, -0.0508, -0.0994, 0.0779, -0.0313, -0.415, 0.5217, -0.2161, 0.046, -0.1052, 0.5156, -0.2391, -0.1148, -0.2006, -0.2139, -0.01, -0.3468, -0.1115, 0.1438, -0.0014, 0.2076, -0.2563]))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv_model.getVectors().rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.spark.sql('use article')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = w2v.spark.sql(\"select * from article_profile where channel_id=18 limit 10\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+--------------------+\n",
      "|article_id|channel_id|            keywords|              topics|\n",
      "+----------+----------+--------------------+--------------------+\n",
      "|     13098|        18|Map(pre -> 0.6040...|[__, object, 属性, ...|\n",
      "|     13248|        18|Map(有限元 -> 5.2929...|[有限元, 代码分析, 案例, z...|\n",
      "|     13401|        18|Map(pre -> 0.2100...|[补码, 字符串, 李白, typ...|\n",
      "|     13723|        18|Map(pre -> 2.1094...|[acc, bstr, 原地, l...|\n",
      "|     14719|        18|Map(pre -> 0.8814...|[__, ctime, cons,...|\n",
      "|     14846|        18|Map(__ -> 2.54674...|[files, __, folde...|\n",
      "|     15173|        18|Map(人人 -> 0.74986...|[cookie, Python爬虫...|\n",
      "|     15194|        18|Map(dif -> 0.7567...|[display, 课程, lis...|\n",
      "|     15237|        18|Map(pre -> 0.5349...|[__, send, sel, c...|\n",
      "|     15322|        18|Map(pre -> 0.5762...|[Pclass, replace,...|\n",
      "+----------+----------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "profile.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.registerTempTable(\"incremental\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "articleKeywordsWeights = w2v.spark.sql(\n",
    "                \"select article_id, channel_id, keyword, weight from incremental LATERAL VIEW explode(keywords) AS keyword, weight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------+-------------------+\n",
      "|article_id|channel_id| keyword|             weight|\n",
      "+----------+----------+--------+-------------------+\n",
      "|     13098|        18|    repr| 0.6326590117716192|\n",
      "|     13098|        18|      __| 2.5401122038114203|\n",
      "|     13098|        18|      属性|0.23645924932468856|\n",
      "|     13098|        18|     pre| 0.6040062287555379|\n",
      "|     13098|        18|    code| 0.9531379029975557|\n",
      "|     13098|        18|     def| 0.5063435861497416|\n",
      "|     13098|        18|   color| 1.1337936117177925|\n",
      "|     13098|        18|      定义| 0.1554380122061322|\n",
      "|     13098|        18| Student| 0.5033771372284416|\n",
      "|     13098|        18|getPrice| 0.7404427038950527|\n",
      "|     13098|        18|      方法|0.08080845613717194|\n",
      "|     13098|        18|     div| 0.3434819820586186|\n",
      "|     13098|        18|     str|0.35999033790156054|\n",
      "|     13098|        18|      pa| 0.6651385256756351|\n",
      "|     13098|        18|   slots| 0.6992789472129189|\n",
      "|     13098|        18| cnblogs|0.33926586102013295|\n",
      "|     13098|        18|      函数|0.15015578405898256|\n",
      "|     13098|        18|   style| 2.4777013955852873|\n",
      "|     13098|        18|      &#| 0.4911011561534254|\n",
      "|     13098|        18|   class|0.28891320463243075|\n",
      "+----------+----------+--------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "articleKeywordsWeights.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "_article_profile = articleKeywordsWeights.join(vectors, vectors.word==articleKeywordsWeights.keyword, \"inner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+-------------------+----------+--------------------+\n",
      "|article_id|channel_id|   keyword|             weight|      word|              vector|\n",
      "+----------+----------+----------+-------------------+----------+--------------------+\n",
      "|     13098|        18|      repr| 0.6326590117716192|      repr|[0.21036092936992...|\n",
      "|     13098|        18|        __| 2.5401122038114203|        __|[0.01188501343131...|\n",
      "|     13098|        18|        属性|0.23645924932468856|        属性|[-0.0808837264776...|\n",
      "|     13098|        18|       pre| 0.6040062287555379|       pre|[0.57123136520385...|\n",
      "|     13098|        18|      code| 0.9531379029975557|      code|[0.36302515864372...|\n",
      "|     13098|        18|       def| 0.5063435861497416|       def|[0.15328533947467...|\n",
      "|     13098|        18|     color| 1.1337936117177925|     color|[0.54077166318893...|\n",
      "|     13098|        18|        定义| 0.1554380122061322|        定义|[-0.0069237630814...|\n",
      "|     13098|        18|   Student| 0.5033771372284416|   Student|[0.18755832314491...|\n",
      "|     13098|        18|  getPrice| 0.7404427038950527|  getPrice|[-0.1144904047250...|\n",
      "|     13098|        18|        方法|0.08080845613717194|        方法|[-0.0597508028149...|\n",
      "|     13098|        18|       div| 0.3434819820586186|       div|[0.11754755675792...|\n",
      "|     13098|        18|       str|0.35999033790156054|       str|[-0.0372486524283...|\n",
      "|     13098|        18|        pa| 0.6651385256756351|        pa|[0.12457559257745...|\n",
      "|     13098|        18|     slots| 0.6992789472129189|     slots|[-0.3247180879116...|\n",
      "|     13098|        18|   cnblogs|0.33926586102013295|   cnblogs|[0.08486368507146...|\n",
      "|     13098|        18|        函数|0.15015578405898256|        函数|[0.08080720901489...|\n",
      "|     13098|        18|     style| 2.4777013955852873|     style|[0.25782978534698...|\n",
      "|     13098|        18|        &#| 0.4911011561534254|        &#|[-0.0150194764137...|\n",
      "|     13098|        18|     class|0.28891320463243075|     class|[-0.0581674352288...|\n",
      "|     13248|        18|    strong|  4.705249850191452|    strong|[0.06607607007026...|\n",
      "|     13248|        18|        矩阵| 2.9867871481396957|        矩阵|[0.67477011680603...|\n",
      "|     13248|        18|      code| 2.3665256806276354|      code|[0.36302515864372...|\n",
      "|     13248|        18|        参数| 0.6498203796828275|        参数|[0.17283125221729...|\n",
      "|     13248|        18|        出力|  4.093381133468962|        出力|[0.02321195974946...|\n",
      "|     13248|        18|        系统| 0.7199439290823474|        系统|[-0.1191022768616...|\n",
      "|     13248|        18|     numpy|  2.625273731033809|     numpy|[0.96511012315750...|\n",
      "|     13248|        18|    matrix| 2.6189002483194237|    matrix|[0.70429068803787...|\n",
      "|     13248|        18|      rray| 2.5310330643792716|      rray|[0.28330472111701...|\n",
      "|     13248|        18|      cyan|  4.808843934532666|      cyan|[0.35614725947380...|\n",
      "|     13248|        18|     zeros| 2.7246588133652736|     zeros|[0.78910171985626...|\n",
      "|     13248|        18|        专业| 1.6073530419233255|        专业|[-0.1485563367605...|\n",
      "|     13248|        18|        .a| 0.6408325228873414|        .a|[-0.0283030755817...|\n",
      "|     13248|        18|        方向| 1.3284434635411801|        方向|[0.04044334590435...|\n",
      "|     13248|        18|        向量|  2.117767625702124|        向量|[0.42050802707672...|\n",
      "|     13248|        18|background|  2.090364256264405|background|[0.78025752305984...|\n",
      "|     13248|        18|    Python| 1.2271370668933776|    Python|[-0.1214548945426...|\n",
      "|     13401|        18|        小写|0.25538666819965045|        小写|[0.19121922552585...|\n",
      "|     13401|        18|      item| 0.1907214431716628|      item|[0.03357587009668...|\n",
      "|     13401|        18|       pre|0.21000278949538911|       pre|[0.57123136520385...|\n",
      "+----------+----------+----------+-------------------+----------+--------------------+\n",
      "only showing top 40 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_article_profile.show(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "articleKeywordVectors = _article_profile.rdd.map(lambda row: (row.article_id, row.channel_id, row.keyword, row.weight * row.vector)).toDF([\"article_id\", \"channel_id\", \"keyword\", \"weightingVector\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------+--------------------+\n",
      "|article_id|channel_id| keyword|     weightingVector|\n",
      "+----------+----------+--------+--------------------+\n",
      "|     13098|        18|    repr|[0.13308673769053...|\n",
      "|     13098|        18|      __|[0.03018926765933...|\n",
      "|     13098|        18|      属性|[-0.0191257052454...|\n",
      "|     13098|        18|     pre|[0.34502730264365...|\n",
      "|     13098|        18|    code|[0.34601303844503...|\n",
      "|     13098|        18|     def|[0.07761504849378...|\n",
      "|     13098|        18|   color|[0.61312345712161...|\n",
      "|     13098|        18|      定义|[-0.0010762159703...|\n",
      "|     13098|        18| Student|[0.09441257176805...|\n",
      "|     13098|        18|getPrice|[-0.0847735848446...|\n",
      "|     13098|        18|      方法|[-0.0048283701284...|\n",
      "|     13098|        18|     div|[0.04037546778136...|\n",
      "|     13098|        18|     str|[-0.0134091549740...|\n",
      "|     13098|        18|      pa|[0.08286002598213...|\n",
      "|     13098|        18|   slots|[-0.2270685226558...|\n",
      "|     13098|        18| cnblogs|[0.02879135118511...|\n",
      "|     13098|        18|      函数|[0.01213366982724...|\n",
      "|     13098|        18|   style|[0.63882521897767...|\n",
      "|     13098|        18|      &#|[-0.0073760822316...|\n",
      "|     13098|        18|   class|[-0.0168053401172...|\n",
      "+----------+----------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "articleKeywordVectors.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 计算文章向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg(row):\n",
    "    x = 0\n",
    "    for v in row.vectors:\n",
    "        x += v\n",
    "    #  将平均向量作为article的向量\n",
    "    return row.article_id, row.channel_id, x / len(row.vectors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "articleKeywordVectors.registerTempTable('tempTable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "articleVector = w2v.spark.sql('select article_id, min(channel_id) channel_id, collect_set(weightingVector) vectors from tempTable group by article_id').rdd.map(avg).toDF(['article_id', 'channel_id', 'articleVector'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+\n",
      "|article_id|channel_id|       articleVector|\n",
      "+----------+----------+--------------------+\n",
      "|     13098|        18|[0.10339950907039...|\n",
      "|     13248|        18|[0.84907054580879...|\n",
      "|     13401|        18|[0.06157120217893...|\n",
      "|     13723|        18|[0.20708073724961...|\n",
      "|     14719|        18|[-0.0405607722081...|\n",
      "|     14846|        18|[0.17945355257543...|\n",
      "|     15173|        18|[-0.2399774663757...|\n",
      "|     15194|        18|[0.08605245220126...|\n",
      "|     15237|        18|[0.02019666206037...|\n",
      "|     15322|        18|[0.11985676790665...|\n",
      "+----------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "articleVector.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(article_id=13098, channel_id=18, articleVector=DenseVector([0.1034, 0.0785, 0.0041, 0.0603, -0.0141, -0.029, 0.0496, 0.1423, -0.0637, 0.01, -0.1751, 0.0785, 0.0409, 0.1243, -0.0123, 0.0188, -0.058, -0.0584, -0.0081, 0.0583, -0.0289, 0.0535, 0.0049, 0.0763, -0.1058, -0.1615, 0.0606, 0.0193, 0.022, -0.1981, -0.0388, 0.0176, 0.2267, 0.0398, -0.1301, 0.0255, -0.1784, -0.0603, 0.0013, -0.0518, 0.1123, -0.0474, -0.1108, 0.0204, 0.0429, 0.0315, 0.0184, 0.2174, -0.0671, 0.0786, -0.0197, -0.0552, 0.1391, 0.0997, 0.098, -0.0035, 0.1513, -0.0479, 0.0127, -0.0037, 0.1215, -0.0365, 0.0724, -0.1241, 0.0419, 0.0564, -0.0454, -0.0452, 0.0281, -0.1254, -0.1335, -0.0174, -0.0413, -0.0709, 0.0937, -0.0294, 0.0517, 0.0954, 0.0809, 0.0077, 0.1265, -0.1395, 0.0913, 0.0066, -0.0008, 0.0983, 0.0209, 0.0487, -0.1136, 0.1168, 0.0356, 0.087, 0.0318, 0.0095, -0.0157, 0.0318, -0.0545, -0.0834, 0.0832, 0.2326]))]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articleVector.rdd.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算相似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "# 选取部分数据做测试\n",
    "article_vector = w2v.spark.sql(\"select article_id, articlevector from article_vector where channel_id=18 limit 10\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = article_vector.select(['article_id', 'articlevector'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _array_to_vector(row):\n",
    "    return row.article_id, Vectors.dense(row.articlevector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.rdd.map(_array_to_vector).toDF(['article_id', 'articleVector'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|article_id|       articleVector|\n",
      "+----------+--------------------+\n",
      "|     13098|[0.10339950907039...|\n",
      "|     13248|[0.84907054580879...|\n",
      "|     13401|[0.06157120217893...|\n",
      "|     13723|[0.20708073724961...|\n",
      "|     14719|[-0.0405607722081...|\n",
      "|     14846|[0.17945355257543...|\n",
      "|     15173|[-0.2399774663757...|\n",
      "|     15194|[0.08605245220126...|\n",
      "|     15237|[0.02019666206037...|\n",
      "|     15322|[0.11985676790665...|\n",
      "+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import BucketedRandomProjectionLSH\n",
    "\n",
    "# 默认4，10，官方推荐使用大小\n",
    "brp = BucketedRandomProjectionLSH(inputCol='articleVector', outputCol='hashes', numHashTables=4.0, bucketLength=10.0)\n",
    "model = brp.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar = model.approxSimilarityJoin(train, train, 2.0, distCol='EuclideanDistance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------------+\n",
      "|            datasetA|            datasetB| EuclideanDistance|\n",
      "+--------------------+--------------------+------------------+\n",
      "|[15237,[0.0201966...|[15237,[0.0201966...|               0.0|\n",
      "|[15194,[0.0860524...|[15237,[0.0201966...|0.8329097179846192|\n",
      "|[13098,[0.1033995...|[13098,[0.1033995...|               0.0|\n",
      "|[15322,[0.1198567...|[15237,[0.0201966...| 0.898816446815378|\n",
      "|[13401,[0.0615712...|[15173,[-0.239977...|1.4193381175720314|\n",
      "|[14719,[-0.040560...|[13098,[0.1033995...|1.4624429314093754|\n",
      "|[15237,[0.0201966...|[13723,[0.2070807...|0.9242292591649734|\n",
      "|[13401,[0.0615712...|[13723,[0.2070807...|0.7932578595105071|\n",
      "|[13401,[0.0615712...|[14719,[-0.040560...|1.4501024819771564|\n",
      "|[15237,[0.0201966...|[15194,[0.0860524...|0.8329097179846192|\n",
      "|[14719,[-0.040560...|[14846,[0.1794535...|1.5597513614699037|\n",
      "|[13098,[0.1033995...|[13723,[0.2070807...| 0.765768247253341|\n",
      "|[14719,[-0.040560...|[13401,[0.0615712...|1.4501024819771564|\n",
      "|[15322,[0.1198567...|[14846,[0.1794535...|1.1211720032710115|\n",
      "|[15194,[0.0860524...|[15173,[-0.239977...| 1.565320662482323|\n",
      "|[15237,[0.0201966...|[13098,[0.1033995...|0.7627248315608527|\n",
      "|[13098,[0.1033995...|[15237,[0.0201966...|0.7627248315608527|\n",
      "|[15322,[0.1198567...|[13098,[0.1033995...|1.1049497082913633|\n",
      "|[13098,[0.1033995...|[13401,[0.0615712...|0.6210444830476037|\n",
      "|[14846,[0.1794535...|[13098,[0.1033995...|0.5752552698237495|\n",
      "+--------------------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "similar.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------+\n",
      "|            datasetA|            datasetB|  EuclideanDistance|\n",
      "+--------------------+--------------------+-------------------+\n",
      "|[13723,[0.2070807...|[13723,[0.2070807...|                0.0|\n",
      "|[15322,[0.1198567...|[15322,[0.1198567...|                0.0|\n",
      "|[13401,[0.0615712...|[13401,[0.0615712...|                0.0|\n",
      "|[14719,[-0.040560...|[14719,[-0.040560...|                0.0|\n",
      "|[15194,[0.0860524...|[15194,[0.0860524...|                0.0|\n",
      "|[13098,[0.1033995...|[13098,[0.1033995...|                0.0|\n",
      "|[14846,[0.1794535...|[14846,[0.1794535...|                0.0|\n",
      "|[13248,[0.8490705...|[13248,[0.8490705...|                0.0|\n",
      "|[15173,[-0.239977...|[15173,[-0.239977...|                0.0|\n",
      "|[15237,[0.0201966...|[15237,[0.0201966...|                0.0|\n",
      "|[15237,[0.0201966...|[13401,[0.0615712...|0.42729625714112773|\n",
      "|[13401,[0.0615712...|[15237,[0.0201966...|0.42729625714112773|\n",
      "|[14846,[0.1794535...|[13098,[0.1033995...| 0.5752552698237495|\n",
      "|[13098,[0.1033995...|[14846,[0.1794535...| 0.5752552698237495|\n",
      "|[13401,[0.0615712...|[13098,[0.1033995...| 0.6210444830476037|\n",
      "|[13098,[0.1033995...|[13401,[0.0615712...| 0.6210444830476037|\n",
      "|[13401,[0.0615712...|[14846,[0.1794535...| 0.6277774927938041|\n",
      "|[14846,[0.1794535...|[13401,[0.0615712...| 0.6277774927938041|\n",
      "|[15194,[0.0860524...|[13401,[0.0615712...| 0.6824896606326648|\n",
      "|[13401,[0.0615712...|[15194,[0.0860524...| 0.6824896606326648|\n",
      "+--------------------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "similar.sort(['EuclideanDistance']).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(datasetA=Row(article_id=15237, articleVector=DenseVector([0.0202, 0.0611, 0.0567, 0.0019, 0.0277, -0.0515, 0.0181, 0.0424, -0.0214, -0.0072, -0.0413, 0.0591, 0.076, 0.0359, 0.0016, 0.0108, 0.0451, -0.0207, 0.0049, 0.0635, -0.0529, 0.0907, 0.0126, 0.0108, -0.0111, -0.0129, -0.019, -0.005, 0.0292, -0.0707, -0.0297, -0.0005, 0.033, -0.0064, -0.0198, 0.0333, -0.0161, 0.0024, -0.0176, -0.0089, -0.0203, -0.0167, -0.0107, -0.0153, -0.0143, 0.0538, 0.0619, -0.0342, -0.0104, -0.0136, 0.0035, -0.0202, 0.0269, 0.0077, 0.0316, -0.0169, 0.0326, -0.0306, 0.0606, -0.0024, 0.0378, -0.0242, 0.0083, -0.0109, 0.0434, 0.0041, 0.0328, -0.0408, 0.0248, -0.0225, 0.0366, 0.0037, -0.0087, -0.0183, -0.0349, 0.0802, -0.0003, -0.0192, 0.0562, -0.0312, 0.043, -0.0167, -0.0184, 0.0033, -0.0167, 0.038, 0.0632, 0.0453, -0.0499, 0.056, 0.0097, 0.0576, 0.0362, -0.0154, 0.0354, 0.0665, -0.0622, -0.0416, -0.0229, 0.0795]), hashes=[DenseVector([-1.0]), DenseVector([-1.0]), DenseVector([-1.0]), DenseVector([0.0])]), datasetB=Row(article_id=15237, articleVector=DenseVector([0.0202, 0.0611, 0.0567, 0.0019, 0.0277, -0.0515, 0.0181, 0.0424, -0.0214, -0.0072, -0.0413, 0.0591, 0.076, 0.0359, 0.0016, 0.0108, 0.0451, -0.0207, 0.0049, 0.0635, -0.0529, 0.0907, 0.0126, 0.0108, -0.0111, -0.0129, -0.019, -0.005, 0.0292, -0.0707, -0.0297, -0.0005, 0.033, -0.0064, -0.0198, 0.0333, -0.0161, 0.0024, -0.0176, -0.0089, -0.0203, -0.0167, -0.0107, -0.0153, -0.0143, 0.0538, 0.0619, -0.0342, -0.0104, -0.0136, 0.0035, -0.0202, 0.0269, 0.0077, 0.0316, -0.0169, 0.0326, -0.0306, 0.0606, -0.0024, 0.0378, -0.0242, 0.0083, -0.0109, 0.0434, 0.0041, 0.0328, -0.0408, 0.0248, -0.0225, 0.0366, 0.0037, -0.0087, -0.0183, -0.0349, 0.0802, -0.0003, -0.0192, 0.0562, -0.0312, 0.043, -0.0167, -0.0184, 0.0033, -0.0167, 0.038, 0.0632, 0.0453, -0.0499, 0.056, 0.0097, 0.0576, 0.0362, -0.0154, 0.0354, 0.0665, -0.0622, -0.0416, -0.0229, 0.0795]), hashes=[DenseVector([-1.0]), DenseVector([-1.0]), DenseVector([-1.0]), DenseVector([0.0])]), EuclideanDistance=0.0)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar.rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
